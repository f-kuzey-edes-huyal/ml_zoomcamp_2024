{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "974f8ab8-e141-41e9-af36-2b5a92b9efa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.1\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.keras.processing.image import load_img\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%matplotlib inline\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications.xception import decode_predictions\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "print(tf.__version__)\n",
    "#!pip install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f69163-57f3-4a0e-af9d-a0eb9d230e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to C:/Users/Kuzey\n"
     ]
    }
   ],
   "source": [
    "#!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to your ZIP file\n",
    "zip_file_path = \"data.zip\"\n",
    "\n",
    "# Destination folder (change if needed)\n",
    "destination_folder = \"C:/Users/Kuzey\"\n",
    "\n",
    "# Ensure the destination folder exists\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Extract the ZIP file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_folder)\n",
    "\n",
    "print(f\"Files extracted to {destination_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c75aa18-eedd-443b-b266-a06786ada164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.17.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2211396b-2eef-4630-b955-6f3556f25178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfba09b-ed41-4444-9ec0-a2d06720be03",
   "metadata": {},
   "source": [
    "Model\n",
    "For this homework we will use Convolutional Neural Network (CNN). Like in the lectures, we'll use Keras.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "- The shape for input should be (200, 200, 3)\n",
    "- Next, create a convolutional layer (Conv2D):\n",
    "- Use 32 filters\n",
    "- Kernel size should be (3, 3) (that's the size of the filter)\n",
    "- Use 'relu' as activation\n",
    "- Reduce the size of the feature map with max pooling (MaxPooling2D)\n",
    "- Set the pooling size to (2, 2)\n",
    "- Turn the multi-dimensional result into vectors using a Flatten layer\n",
    "- Next, add a Dense layer with 64 neurons and 'relu' activation\n",
    "- Finally, create the Dense layer with 1 neuron - this will be the output\n",
    "- The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "- As optimizer use SGD with the following parameters:\n",
    "\n",
    "- SGD(lr=0.002, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10019df9-fbfe-476d-a265-ed526623a925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "380ed3d7-bc91-45cd-ad04-59f00eac9524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuzey\\Anaconda3\\envs\\ml-zoomcamp\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">313632</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">20,072,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m313632\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │      \u001b[38;5;34m20,072,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,073,473</span> (76.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,073,473\u001b[0m (76.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,073,473</span> (76.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,073,473\u001b[0m (76.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer with Conv2D\n",
    "    model.add(Conv2D(\n",
    "        filters=32, \n",
    "        kernel_size=(3, 3), \n",
    "        activation='relu', \n",
    "        input_shape=(200, 200, 3)\n",
    "    ))\n",
    "    \n",
    "    # MaxPool\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Flatten \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Dense layer\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "    # Output for binary classification\n",
    "    model.add(Dense(1, activation='sigmoid'))  # 'sigmoid' for binary classification\n",
    "    \n",
    "    # Compile the model with SGD optimizer\n",
    "    optimizer = SGD(learning_rate=0.002, momentum=0.8)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "cnn_model = create_model()\n",
    "\n",
    "# Print the model summary\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dc93a6-8e22-4c27-ad4e-0f589c678948",
   "metadata": {},
   "source": [
    "__Q1.__ Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "- mean squared error\n",
    "- __binary crossentropy__\n",
    "- categorical crossentropy\n",
    "- cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9668c5-4c7c-46a5-9c9b-aebd4b2a275c",
   "metadata": {},
   "source": [
    "__Q2.__  What's the total number of parameters of the model? You can use the summary method for that.\n",
    "\n",
    "- 896\n",
    "- 11214912\n",
    "- 15896912\n",
    "- __20072512__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57277a30-9cf1-4f01-835b-d62e8a309d4e",
   "metadata": {},
   "source": [
    "For the next two questions, use the following data generator for both train and test sets:\n",
    "\n",
    "`ImageDataGenerator(rescale=1./255)`\n",
    "\n",
    "We don't need to do any additional pre-processing for the images.\n",
    "\n",
    "When reading the data from train/test directories, check the class_mode parameter. Which value should it be for a binary classification problem?\n",
    "Use `batch_size=20`\n",
    "\n",
    "Use shuffle=True for both training and test sets.\n",
    "\n",
    "For training use `.fit()` with the following params:\n",
    "\n",
    "\n",
    "`model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b19df2-0022-4641-8a8a-96818b3d7d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n",
      "Found 201 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './data/train',\n",
    "    target_size=(200, 200),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    "   \n",
    ")\n",
    " \n",
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './data/test',\n",
    "    target_size=(200, 200),\n",
    "    batch_size=20,\n",
    "    shuffle=False,\n",
    "    class_mode='binary'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93bca296-fbad-42f2-84f9-ac6f3f419be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuzey\\Anaconda3\\envs\\ml-zoomcamp\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 449ms/step - accuracy: 0.5258 - loss: 0.6990 - val_accuracy: 0.6119 - val_loss: 0.6754\n",
      "Epoch 2/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 403ms/step - accuracy: 0.6691 - loss: 0.6128 - val_accuracy: 0.6468 - val_loss: 0.6165\n",
      "Epoch 3/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 392ms/step - accuracy: 0.7149 - loss: 0.5765 - val_accuracy: 0.6219 - val_loss: 0.6564\n",
      "Epoch 4/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 379ms/step - accuracy: 0.6935 - loss: 0.5707 - val_accuracy: 0.6716 - val_loss: 0.6019\n",
      "Epoch 5/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 391ms/step - accuracy: 0.7429 - loss: 0.5112 - val_accuracy: 0.6368 - val_loss: 0.6252\n",
      "Epoch 6/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 384ms/step - accuracy: 0.7639 - loss: 0.4977 - val_accuracy: 0.5672 - val_loss: 0.7499\n",
      "Epoch 7/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 385ms/step - accuracy: 0.7155 - loss: 0.5311 - val_accuracy: 0.6816 - val_loss: 0.5812\n",
      "Epoch 8/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 387ms/step - accuracy: 0.8002 - loss: 0.4538 - val_accuracy: 0.6766 - val_loss: 0.5826\n",
      "Epoch 9/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 390ms/step - accuracy: 0.8070 - loss: 0.4112 - val_accuracy: 0.6766 - val_loss: 0.5775\n",
      "Epoch 10/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 387ms/step - accuracy: 0.8168 - loss: 0.4105 - val_accuracy: 0.6866 - val_loss: 0.5918\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model =  create_model()\n",
    " \n",
    "history = model.fit(train_ds, epochs=10,  validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490ace67-87c3-47d8-85d4-1dc37fff00e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e635c487-e571-4332-a516-55146b66e278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of Training Accuracy: 0.75\n",
      "Standard Deviation of Training Loss: 0.073\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "training_accuracy = history.history['accuracy']  \n",
    "training_loss = history.history['loss'] \n",
    "\n",
    "\n",
    "median_accuracy = np.median(training_accuracy)\n",
    "\n",
    "\n",
    "std_dev_loss = np.std(training_loss)\n",
    "\n",
    "print(f\"Median of Training Accuracy: {median_accuracy:.2f}\")\n",
    "print(f\"Standard Deviation of Training Loss: {std_dev_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed88fca0-e925-4b1a-ad38-0df905d278d0",
   "metadata": {},
   "source": [
    "__Question 3__\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "- 0.10\n",
    "- 0.32\n",
    "- 0.50\n",
    "- __0.72__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26636de-6df1-475c-b645-b39382e3d87c",
   "metadata": {},
   "source": [
    "__Question 4__\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "- 0.028\n",
    "- __0.068__\n",
    "- 0.128\n",
    "- 0.168"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0779e42-cf7d-4add-b12e-7d00969d8679",
   "metadata": {},
   "source": [
    "__Data Augmentation__\n",
    "\n",
    "For the next two questions, we'll generate more data using data augmentations.\n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "- `rotation_range=50,`\n",
    "- `width_shift_range=0.1,`\n",
    "- `height_shift_range=0.1,`\n",
    "- `zoom_range=0.1,`\n",
    "- `horizontal_flip=True,`\n",
    "- `fill_mode='nearest'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214e018-2a32-4e5e-a019-622bc64a87bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1e55d3c-7615-44bc-a3c5-3571ac91467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=10,\n",
    "    height_shift_range=10,\n",
    "    shear_range=10,\n",
    "    zoom_range=0.1,\n",
    "    cval=0.0,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55834a75-33be-41c2-ade8-411d8305c47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './data/train',\n",
    "    target_size=(200, 200),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    "   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2adc5e1-8afa-4844-a396-087396c49ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 536ms/step - accuracy: 0.6037 - loss: 0.7656 - val_accuracy: 0.5400 - val_loss: 0.7825\n",
      "Epoch 2/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 515ms/step - accuracy: 0.6553 - loss: 0.6054 - val_accuracy: 0.5050 - val_loss: 0.8102\n",
      "Epoch 3/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 519ms/step - accuracy: 0.7476 - loss: 0.5330 - val_accuracy: 0.4850 - val_loss: 0.8718\n",
      "Epoch 4/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 519ms/step - accuracy: 0.6790 - loss: 0.5780 - val_accuracy: 0.4950 - val_loss: 0.8310\n",
      "Epoch 5/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 519ms/step - accuracy: 0.6802 - loss: 0.5946 - val_accuracy: 0.4800 - val_loss: 1.0380\n",
      "Epoch 6/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 538ms/step - accuracy: 0.7380 - loss: 0.5531 - val_accuracy: 0.4950 - val_loss: 0.8693\n",
      "Epoch 7/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 537ms/step - accuracy: 0.7035 - loss: 0.5650 - val_accuracy: 0.5050 - val_loss: 0.8580\n",
      "Epoch 8/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 542ms/step - accuracy: 0.7699 - loss: 0.4959 - val_accuracy: 0.4750 - val_loss: 1.0535\n",
      "Epoch 9/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 543ms/step - accuracy: 0.7371 - loss: 0.5185 - val_accuracy: 0.4900 - val_loss: 0.9358\n",
      "Epoch 10/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 548ms/step - accuracy: 0.7480 - loss: 0.4964 - val_accuracy: 0.4800 - val_loss: 0.9563\n",
      "Mean test loss over 10 additional epochs: 0.900645089149475\n"
     ]
    }
   ],
   "source": [
    "# Continue training the model for 10 more epochs\n",
    "history = model.fit(\n",
    "    train_ds,                     # Augmented data generator\n",
    "    batch_size=20,\n",
    "    epochs=10,                    # Train for 10 more epochs\n",
    "    validation_data=val_ds,       # Validation data (assumed to be prepared)\n",
    "    validation_steps=val_ds.samples // val_ds.batch_size,  # Validation steps\n",
    ")\n",
    "\n",
    "# Optionally, you can save the updated model\n",
    "# model.save('path_to_save_model')  # Save the updated model\n",
    "\n",
    "# Calculate the mean of test loss for all the epochs\n",
    "test_loss = history.history['val_loss']  # Get the validation loss history\n",
    "mean_test_loss = np.mean(test_loss)     # Calculate the mean of the test loss\n",
    "\n",
    "print(f'Mean test loss over 10 additional epochs: {mean_test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa0b853b-6952-4fa0-96fd-1ed428b40c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test accuracy for epochs 6 to 10: 0.4890\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'history' is the object returned from model.fit() after training for 10 more epochs\n",
    "val_accuracy = history.history['val_accuracy']  # Get the validation accuracy history\n",
    "\n",
    "# Extract the validation accuracy for epochs 6 to 10 (index 5 to 9)\n",
    "val_accuracy_last_5_epochs = val_accuracy[5:10]  # Epochs 6 to 10 correspond to indices 5 to 9\n",
    "\n",
    "# Calculate the average of test accuracy for epochs 6 to 10\n",
    "average_val_accuracy = np.mean(val_accuracy_last_5_epochs)\n",
    "\n",
    "print(f'Average test accuracy for epochs 6 to 10: {average_val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd99251a-7706-4032-abdf-428845760894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
