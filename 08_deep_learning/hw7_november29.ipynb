{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "974f8ab8-e141-41e9-af36-2b5a92b9efa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.1\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.keras.processing.image import load_img\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%matplotlib inline\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications.xception import decode_predictions\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "print(tf.__version__)\n",
    "#!pip install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f69163-57f3-4a0e-af9d-a0eb9d230e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to C:/Users/Kuzey\n"
     ]
    }
   ],
   "source": [
    "#!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to your ZIP file\n",
    "zip_file_path = \"data.zip\"\n",
    "\n",
    "# Destination folder (change if needed)\n",
    "destination_folder = \"C:/Users/Kuzey\"\n",
    "\n",
    "# Ensure the destination folder exists\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Extract the ZIP file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_folder)\n",
    "\n",
    "print(f\"Files extracted to {destination_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c75aa18-eedd-443b-b266-a06786ada164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.17.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2211396b-2eef-4630-b955-6f3556f25178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfba09b-ed41-4444-9ec0-a2d06720be03",
   "metadata": {},
   "source": [
    "Model\n",
    "For this homework we will use Convolutional Neural Network (CNN). Like in the lectures, we'll use Keras.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "- The shape for input should be (200, 200, 3)\n",
    "- Next, create a convolutional layer (Conv2D):\n",
    "- Use 32 filters\n",
    "- Kernel size should be (3, 3) (that's the size of the filter)\n",
    "- Use 'relu' as activation\n",
    "- Reduce the size of the feature map with max pooling (MaxPooling2D)\n",
    "- Set the pooling size to (2, 2)\n",
    "- Turn the multi-dimensional result into vectors using a Flatten layer\n",
    "- Next, add a Dense layer with 64 neurons and 'relu' activation\n",
    "- Finally, create the Dense layer with 1 neuron - this will be the output\n",
    "- The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "- As optimizer use SGD with the following parameters:\n",
    "\n",
    "- SGD(lr=0.002, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10019df9-fbfe-476d-a265-ed526623a925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aaa36c2-3185-45e2-abcb-bb4bf81e4acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">313632</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">20,072,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m313632\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │      \u001b[38;5;34m20,072,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,073,473</span> (76.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,073,473\u001b[0m (76.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,073,473</span> (76.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,073,473\u001b[0m (76.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def make_model(learning_rate=0.002, size_inner=64):\n",
    "    # Input layer\n",
    "    inputs = keras.Input(shape=(200, 200, 3))\n",
    "    \n",
    "    # Convolutional layer with 32 filters and ReLU activation\n",
    "    x = layers.Conv2D(\n",
    "        filters=32, \n",
    "        kernel_size=(3, 3), \n",
    "        activation='relu'\n",
    "    )(inputs)\n",
    "    \n",
    "    # MaxPooling layer to reduce feature map size\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    # Flatten layer to convert feature maps into a 1D vector\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    # Dense layer with 64 neurons and ReLU activation\n",
    "    x = layers.Dense(size_inner, activation='relu')(x)\n",
    "    \n",
    "    # Output Dense layer with 1 neuron and sigmoid activation\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)  # Sigmoid for binary classification\n",
    "    \n",
    "    # Create the model\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model with SGD optimizer\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.8)\n",
    "    loss = keras.losses.BinaryCrossentropy()  # Sigmoid automatically matches this loss\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "cnn_model = make_model()\n",
    "\n",
    "# Print the model summary\n",
    "cnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dc93a6-8e22-4c27-ad4e-0f589c678948",
   "metadata": {},
   "source": [
    "__Q1.__ Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "- mean squared error\n",
    "- __binary crossentropy__\n",
    "- categorical crossentropy\n",
    "- cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9668c5-4c7c-46a5-9c9b-aebd4b2a275c",
   "metadata": {},
   "source": [
    "__Q2.__  What's the total number of parameters of the model? You can use the summary method for that.\n",
    "\n",
    "- 896\n",
    "- 11214912\n",
    "- 15896912\n",
    "- __20072512__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57277a30-9cf1-4f01-835b-d62e8a309d4e",
   "metadata": {},
   "source": [
    "For the next two questions, use the following data generator for both train and test sets:\n",
    "\n",
    "`ImageDataGenerator(rescale=1./255)`\n",
    "\n",
    "We don't need to do any additional pre-processing for the images.\n",
    "\n",
    "When reading the data from train/test directories, check the class_mode parameter. Which value should it be for a binary classification problem?\n",
    "Use `batch_size=20`\n",
    "\n",
    "Use shuffle=True for both training and test sets.\n",
    "\n",
    "For training use `.fit()` with the following params:\n",
    "\n",
    "\n",
    "`model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b19df2-0022-4641-8a8a-96818b3d7d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n",
      "Found 201 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './data/train',\n",
    "    target_size=(200, 200),\n",
    "    batch_size=20,\n",
    "    shuffle=True,\n",
    "    class_mode='binary'\n",
    "   \n",
    ")\n",
    " \n",
    "val_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './data/test',\n",
    "    target_size=(200, 200),\n",
    "    batch_size=20,\n",
    "    shuffle=True,\n",
    "    class_mode='binary'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93bca296-fbad-42f2-84f9-ac6f3f419be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuzey\\Anaconda3\\envs\\ml-zoomcamp\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 445ms/step - accuracy: 0.5635 - loss: 0.6878 - val_accuracy: 0.6119 - val_loss: 0.6316\n",
      "Epoch 2/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 399ms/step - accuracy: 0.6427 - loss: 0.6004 - val_accuracy: 0.6617 - val_loss: 0.6180\n",
      "Epoch 3/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 396ms/step - accuracy: 0.7458 - loss: 0.5292 - val_accuracy: 0.6368 - val_loss: 0.6317\n",
      "Epoch 4/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 395ms/step - accuracy: 0.7157 - loss: 0.5610 - val_accuracy: 0.6617 - val_loss: 0.6382\n",
      "Epoch 5/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 392ms/step - accuracy: 0.7628 - loss: 0.5000 - val_accuracy: 0.6418 - val_loss: 0.6328\n",
      "Epoch 6/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 389ms/step - accuracy: 0.7535 - loss: 0.4938 - val_accuracy: 0.6617 - val_loss: 0.6390\n",
      "Epoch 7/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 393ms/step - accuracy: 0.7706 - loss: 0.4888 - val_accuracy: 0.6716 - val_loss: 0.6228\n",
      "Epoch 8/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 394ms/step - accuracy: 0.7845 - loss: 0.4621 - val_accuracy: 0.7065 - val_loss: 0.5801\n",
      "Epoch 9/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 387ms/step - accuracy: 0.8088 - loss: 0.4081 - val_accuracy: 0.6866 - val_loss: 0.5754\n",
      "Epoch 10/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 391ms/step - accuracy: 0.7950 - loss: 0.4204 - val_accuracy: 0.6617 - val_loss: 0.6937\n"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    " \n",
    "history = cnn_model.fit(train_ds, epochs=10,  validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490ace67-87c3-47d8-85d4-1dc37fff00e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e635c487-e571-4332-a516-55146b66e278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of Training Accuracy: 0.76\n",
      "Standard Deviation of Training Loss: 0.079\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "training_accuracy = history.history['accuracy']  \n",
    "training_loss = history.history['loss'] \n",
    "\n",
    "\n",
    "median_accuracy = np.median(training_accuracy)\n",
    "\n",
    "\n",
    "std_dev_loss = np.std(training_loss)\n",
    "\n",
    "print(f\"Median of Training Accuracy: {median_accuracy:.2f}\")\n",
    "print(f\"Standard Deviation of Training Loss: {std_dev_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed88fca0-e925-4b1a-ad38-0df905d278d0",
   "metadata": {},
   "source": [
    "__Question 3__\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "- 0.10\n",
    "- 0.32\n",
    "- 0.50\n",
    "- __0.72__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26636de-6df1-475c-b645-b39382e3d87c",
   "metadata": {},
   "source": [
    "__Question 4__\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "- 0.028\n",
    "- __0.068__\n",
    "- 0.128\n",
    "- 0.168"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0779e42-cf7d-4add-b12e-7d00969d8679",
   "metadata": {},
   "source": [
    "__Data Augmentation__\n",
    "\n",
    "For the next two questions, we'll generate more data using data augmentations.\n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "- `rotation_range=50,`\n",
    "- `width_shift_range=0.1,`\n",
    "- `height_shift_range=0.1,`\n",
    "- `zoom_range=0.1,`\n",
    "- `horizontal_flip=True,`\n",
    "- `fill_mode='nearest'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214e018-2a32-4e5e-a019-622bc64a87bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1e55d3c-7615-44bc-a3c5-3571ac91467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55834a75-33be-41c2-ade8-411d8305c47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    "train_ds_new = train_gen.flow_from_directory(\n",
    "    './data/train',\n",
    "    target_size=(200, 200),\n",
    "    batch_size=20,\n",
    "    shuffle=True,\n",
    "    class_mode='binary'\n",
    "   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea3a3d-dd94-4c2e-971f-507543b433cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2adc5e1-8afa-4844-a396-087396c49ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 531ms/step - accuracy: 0.6959 - loss: 0.6192 - val_accuracy: 0.7114 - val_loss: 0.5503\n",
      "Epoch 2/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 542ms/step - accuracy: 0.6548 - loss: 0.6101 - val_accuracy: 0.7413 - val_loss: 0.5485\n",
      "Epoch 3/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 541ms/step - accuracy: 0.7104 - loss: 0.5635 - val_accuracy: 0.7164 - val_loss: 0.5755\n",
      "Epoch 4/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 517ms/step - accuracy: 0.7049 - loss: 0.5697 - val_accuracy: 0.6567 - val_loss: 0.6407\n",
      "Epoch 5/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 524ms/step - accuracy: 0.6846 - loss: 0.5724 - val_accuracy: 0.7114 - val_loss: 0.5692\n",
      "Epoch 6/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 520ms/step - accuracy: 0.7488 - loss: 0.5490 - val_accuracy: 0.7264 - val_loss: 0.5331\n",
      "Epoch 7/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 522ms/step - accuracy: 0.7095 - loss: 0.5778 - val_accuracy: 0.6766 - val_loss: 0.6209\n",
      "Epoch 8/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 526ms/step - accuracy: 0.7314 - loss: 0.5377 - val_accuracy: 0.7214 - val_loss: 0.5842\n",
      "Epoch 9/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 558ms/step - accuracy: 0.7405 - loss: 0.5308 - val_accuracy: 0.7363 - val_loss: 0.5428\n",
      "Epoch 10/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 568ms/step - accuracy: 0.7279 - loss: 0.5657 - val_accuracy: 0.7413 - val_loss: 0.5098\n",
      "Mean test loss over 10 additional epochs: 0.5674814760684967\n"
     ]
    }
   ],
   "source": [
    "# Continue training the model for 10 more epochs\n",
    "history = cnn_model.fit(\n",
    "    train_ds_new,                     # Augmented data generator\n",
    "    batch_size=20,\n",
    "    epochs=10,                    # Train for 10 more epochs\n",
    "    validation_data=val_ds# Validation data (assumed to be prepared)\n",
    ")\n",
    "   \n",
    "\n",
    "# Optionally, you can save the updated model\n",
    "# model.save('path_to_save_model')  # Save the updated model\n",
    "\n",
    "# Calculate the mean of test loss for all the epochs\n",
    "test_loss = history.history['val_loss']  # Get the validation loss history\n",
    "mean_test_loss = np.mean(test_loss)     # Calculate the mean of the test loss\n",
    "\n",
    "print(f'Mean test loss over 10 additional epochs: {mean_test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107a315c-dee6-47c8-9721-c8477d854fd4",
   "metadata": {},
   "source": [
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "\n",
    "Note: make sure you don't re-create the model - we want to continue training the model we already started training.\n",
    "\n",
    "__Question 5__ What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "- 0.26\n",
    "- __0.56__\n",
    "- 0.86\n",
    "- 1.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa0b853b-6952-4fa0-96fd-1ed428b40c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test accuracy for epochs 6 to 10: 0.7204\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'history' is the object returned from model.fit() after training for 10 more epochs\n",
    "val_accuracy = history.history['val_accuracy']  # Get the validation accuracy history\n",
    "\n",
    "# Extract the validation accuracy for epochs 6 to 10 (index 5 to 9)\n",
    "val_accuracy_last_5_epochs = val_accuracy[5:10]  # Epochs 6 to 10 correspond to indices 5 to 9\n",
    "\n",
    "# Calculate the average of test accuracy for epochs 6 to 10\n",
    "average_val_accuracy = np.mean(val_accuracy_last_5_epochs)\n",
    "\n",
    "print(f'Average test accuracy for epochs 6 to 10: {average_val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd99251a-7706-4032-abdf-428845760894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.711442768573761, 0.7412935495376587, 0.7164179086685181, 0.6567164063453674, 0.711442768573761, 0.7263681888580322, 0.676616907119751, 0.7213930487632751, 0.7363184094429016, 0.7412935495376587]\n"
     ]
    }
   ],
   "source": [
    "print(history.history['val_accuracy'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14df5fd3-17a8-4881-a128-9a359c9d4d7b",
   "metadata": {},
   "source": [
    "__Question 6__ What's the average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?\n",
    "\n",
    "- 0.31\n",
    "- 0.51\n",
    "- __0.71__\n",
    "- 0.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2f835-638e-4791-a2ec-aa2befb171c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
